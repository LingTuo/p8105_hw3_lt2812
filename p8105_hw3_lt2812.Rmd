---
title: "Homework 3"
author: Ling Tuo
date: 10/06/2020
output: 
  github_document:
    toc: true
---

This is my solution to HW3. 

```{r setup, include = FALSE}
library(p8105.datasets)
library(tidyverse)
library(patchwork)
library(ggplot2)
library(hexbin)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d()
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by users. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?
```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Let's make a plot.
```{r}
plot_p1 = 
  instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

ggsave("plot_p1.png", plot_p1)
plot_p1
```

Let's make a table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


Apples vs ice cream.

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```


## Problem 2

 - Firstly, load and tidy data.

```{r message = FALSE}
accel_data = read_csv(file = "./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "min_of_day",
    names_prefix = "activity.",
    values_to = "activity_count"
    ) %>% 
  mutate(
    day = factor(day),
    min_of_day = as.numeric(min_of_day),
    day_of_week = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend"
      )
    ) 
```

This dataset has `r nrow(accel_data)` rows and `r ncol(accel_data)` columns. Observations are activity counts of a person with CHF in orders by minutes of a 24-hour day. There are time variables -- week, day ID, dayï¼Œ minute of the day, day of the week(weekday or weekend) and activity counts variable. 


 - Then, calculate the total activity over the day.
```{r eval = FALSE}
accel_data %>% 
  group_by(week, day) %>% 
  summarize(sum_activity_count = sum(activity_count)) %>% 
  pivot_wider(
    names_from = day,
    values_from = sum_activity_count
  ) %>% 
  select(week, Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday) %>% 
  knitr::kable()
```

According to the table, the person tended to have more stable total activity time on Tuesday and Wednesday. It shows that his activity time are higher in the first three weeks on weekends.


 - Lastly, make the plot of the 24-hour activity time courses for each day.
 
```{r}
plot_p2 = 
  accel_data %>% 
  group_by(week, day) %>% 
  ggplot(aes(x = min_of_day, y = activity_count, color = day, alpha = .3)) + 
  geom_point() +
  geom_line() +
  labs(
    title = "24-hour activity time courses for each day",
    x = "Minute of the day/hours(min/h)",
    y = "Activity counts") + 
  scale_x_continuous(
    breaks = c(0, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("0/0h", "180/3h", "360/6h", "540/9h", "720/12h", "900/15h", "1080/18h", "1260/21h", "1440/24h")
  )

ggsave("plot_p2.png", plot_p2)
plot_p2
```

The plot indicates that there are low activity in the night, from 9 p.m to 6 a.m. and there are a few peaks unevenly spread during daytime from Monday to Sunday. Especially, the most frequently activity time is around 9 p.m.

## Problem 3

 - Firstly, load and tidy the dataset.

```{r}
data("ny_noaa")
ny_noaa_tidy =
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    prcp = prcp/10,
    across(tmax:tmin, as.numeric),
    tmax = tmax/10,
    tmin = tmin/10
  )
```

```{r}
ny_noaa_tidy %>% 
  count(snow, name = "n_obs")
```

This dataset contains `r nrow(ny_noaa_tidy)` rows and `r ncol(ny_noaa_tidy)` columns. Observations are the five core variables for all New York state weather stations from 1981 through 2010. 

There are order variables - id, date(year, month, day) and the core variables -- Precipitation(mm), Snowfall(mm), Snow depth(mm), Maximum temperature(degrees C) and Minimum temperature(degrees C). 

Also, there are `r sum(is.na(pull(ny_noaa_tidy,prcp))) ` missing data in Precipitation, `r sum(is.na(pull(ny_noaa_tidy,snow))) ` missing data in Snowfall, `r sum(is.na(pull(ny_noaa_tidy,snwd))) ` missing data in Snow depth, `r sum(is.na(pull(ny_noaa_tidy,tmax))) ` missing data in Maximum temperature, `r sum(is.na(pull(ny_noaa_tidy,tmin))) ` missing data in Minimum temperature. The number of missing data is large, especially temperature values(almost 50%).

For snowfall, the most commonly observed values is 0, which indicates that New York mostly does not have snow maybe related to the geographic conditions and climates.


 - Then, make plots of average max temperature in January and July in each station across years.
 
```{r warning = FALSE}
plot_max = 
  ny_noaa_tidy %>% 
  group_by(id, year, month) %>% 
  filter(month %in% c("01", "07")) %>% 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_tmax, color = id, group = id)) + 
  geom_point(alpha = .3) +
  geom_path(alpha = .3) +
  theme(legend.position = 'none') +
  facet_grid(. ~ month) +
  labs(
    title = "Average max temperature in January and July",
    x = "year",
    y = "average maximum temperature"
    ) +
  scale_x_discrete(breaks = c("1981", "1986", "1991", "1996", "2001", "2006", "2010"))
  
ggsave("plot_max.png", plot_max)
plot_max
```

According to the plot, the average max temperature in Janurary kept fluctuated from 1981 to 2010 with a slightly rising trend in most of stations. In July, the average max temperatures are similarly unstable. And there are a few outliers much lower than normal values.


 - Finally, (i) make a plot of tmax vs tmin for the full dataset
 
```{r}
plot_temp = 
  ny_noaa_tidy %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex(alpha = .5, na.rm = TRUE) +
  labs(
    title = "tmin vs tmax",
    x = "tmin(C)",
    y = "tmax(C)"
    ) +
  theme(legend.position = 'right')
```

A large number of values gathered around (10, 20) and there are several outliers.


(ii) make a plot showing the distribution of snowfall values and combine two plots.

```{r}
plot_snow = 
  ny_noaa_tidy %>% 
  filter(snow < 100 & snow > 0) %>% 
  ggplot(aes(x = snow, y = year)) +
  geom_boxplot() + 
  labs(
    title = "Distribution of snowfall",
    x = "snowfall(mm)",
    y = "year"
    ) 

plot_temp / plot_snow
ggsave("plot_p3.png", plot_temp / plot_snow)
```

The mean and minimum values are almost equal in the plot, most of maximum values are close as well. The snowfall in 1998, 2006 and 2010 seems to be more unique than other years.
